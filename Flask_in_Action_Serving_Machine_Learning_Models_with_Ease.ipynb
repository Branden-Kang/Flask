{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHc7BPISMxssg+teBaqQVE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@bragadeeshs/flask-in-action-serving-machine-learning-models-with-ease-99c43f867f50)"
      ],
      "metadata": {
        "id": "Qd_ypYzEBh84"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XLJfQ-jA1ZY",
        "outputId": "54baf641-9674-4210-d229-091f3a00ce34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Logistic Regression classifier\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Train the classifier\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Save the model to disk\n",
        "joblib.dump(classifier, 'model.pkl')\n",
        "\n",
        "# Optionally: Make predictions on the test set and evaluate the classifier\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Welcome to the Iris Classifier!\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "bfYg0hfeA8d0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Create a Flask application\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the trained model (Ensure 'model.pkl' is in the same directory)\n",
        "model = joblib.load('model.pkl')\n",
        "\n",
        "# Route for inference\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    # Get data from POST request\n",
        "    data = request.get_json(force=True)\n",
        "\n",
        "    # Convert data into numpy array\n",
        "    predict_request = [data['sepal_length'], data['sepal_width'],\n",
        "                       data['petal_length'], data['petal_width']]\n",
        "    predict_request = np.array([predict_request])\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(predict_request)\n",
        "\n",
        "    # Return prediction\n",
        "    return jsonify({'prediction': str(prediction[0])})\n",
        "\n",
        "# Start the Flask app\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ],
      "metadata": {
        "id": "9v731Gx4BNT0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "curl -X POST -H \"Content-Type: application/json\" -d '{\"sepal_length\": 5.1, \"sepal_width\": 3.5, \"petal_length\": 1.4, \"petal_width\": 0.2}' http://localhost:5000/predict\n",
        "```"
      ],
      "metadata": {
        "id": "3dIpI2QUBega"
      }
    }
  ]
}